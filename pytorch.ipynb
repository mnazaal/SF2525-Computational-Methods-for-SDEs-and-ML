{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a PyTorch implementation for the paper \"Solving stochastic differential equations and Kolmogorov equations by means of deep learning\" by Christian Beck et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal as mvn\n",
    "# Honestly though I wanted to do this with JAX+STAX (or FLAX if anyone ever had the guts to use a 3 month old library for something like this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItoDiffusion:\n",
    "    def __init__(self, mu, sigma, N):\n",
    "        # Initializing the Ito Diffusion\n",
    "        # mu    :: R^dxJ -> R^dxJ\n",
    "        # sigma :: R^dxJ -> R^dxdxJ\n",
    "        # where J is the batch size\n",
    "        # N :: Int (Number of points in discretization)\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        self.N = N\n",
    "    \n",
    "    def sample(self, x, T):\n",
    "        # Generate J samples of X_T^x\n",
    "        # x :: R^dxJ\n",
    "        dt        = T/self.N\n",
    "        self.d    = x.size(0)\n",
    "        batchsize = x.size(1)\n",
    "        for i in range(self.N):\n",
    "            x = x + self.mu(x)*dt + self.sigma(x)*mvn(torch.zeros(self.d), dt*torch.eye(self.d)).sample([batchsize]).T\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCNN(nn.Module):\n",
    "    def __init__(self, dim, hidden_layers):\n",
    "        # dim    :: Int (Input dimension and also neurons in each hidden layer)\n",
    "        # hidden :: Int (Number of hidden layers)\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential()\n",
    "        for i in range(hidden_layers):\n",
    "            self.model.add_module(\"Hidden\"+str(i), nn.Linear(dim,dim))\n",
    "            self.model.add_module(\"Batch norm \"+str(i),nn.BatchNorm1d(dim))\n",
    "            self.model.add_module(\"Actvation \"+str(i),nn.Tanh())\n",
    "        self.model.add_module(\"Output\",nn.Linear(dim,1))\n",
    "        \n",
    "\n",
    "    def forward(self,x):\n",
    "        # x :: R^d (Spatial point)\n",
    "        return self.model(x)\n",
    "        # I know, this makes is harder to debug comparing to running the \n",
    "        # input through each layer separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lp_rel_error(neural_net, exact_sol, a,b,d, N,p):\n",
    "    # neural_net :: FCNN (instance of neural network)\n",
    "    # exact_sol  :: RxR^d -> R (exact solution of the PDE)\n",
    "    # a          :: Float (a in [a,b]^d)\n",
    "    # b          :: Float (b in [a,b]^d)\n",
    "    # d          :: Int (d in [a,b]^d)\n",
    "    # N          :: Int (Number of points to sample in the MC estimate)\n",
    "    # p          :: Int (p in the Lp)\n",
    "    spatial_points = (a-b)*torch.rand(N,d) + b\n",
    "    u_exact        = exact_sol(spatial_points)\n",
    "    return float((torch.mean(torch.abs((neural_net(spatial_points)[:,0] - u_exact)/u_exact).pow(p))).pow(1/p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 L1 error is 0.9761679768562317, L2 error is 0.9761002063751221 and loss function value is 21.64076805114746\n",
      "Step 10 L1 error is 0.9777742028236389, L2 error is 0.9780119061470032 and loss function value is 21.24695587158203\n",
      "Step 20 L1 error is 0.9781864285469055, L2 error is 0.9782872200012207 and loss function value is 21.14417266845703\n",
      "Step 30 L1 error is 0.9766857624053955, L2 error is 0.9769785404205322 and loss function value is 20.78600311279297\n",
      "Step 40 L1 error is 0.9725968241691589, L2 error is 0.9739687442779541 and loss function value is 20.484375\n"
     ]
    }
   ],
   "source": [
    "# Heat equation approximation\n",
    "T,N   = 1,1      # Time value we solve PDE for, number of discretization points to sample Ito diffusion\n",
    "a,b = 0,1        # a,b in [a,b]^d\n",
    "d   = 10         # d   in [a,b]^d\n",
    "s   = 3          # total number of layers excluding input (including output, meaning we have s-1 hidden layers)\n",
    "m   = 35000      # SGD iterations\n",
    "J   = 8192\n",
    "learning_rate = 0.001\n",
    "\n",
    "# The Ito diffusion corresponding to the Heat equation is Brownian motion. Here we define the initial condition as \n",
    "# u(0,x)=||x||2 (squared Euclidean norm) and via an Ansatz you can get the exact solution as u(t,x) = ||x||2 + td\n",
    "brownian_motion = ItoDiffusion(lambda x: torch.zeros(x.size(0),x.size(1)), lambda x: torch.sqrt(torch.tensor(2.0)), N)\n",
    "phi = lambda x: torch.norm(x,2,1)\n",
    "u   = lambda x: phi(x) + T*d\n",
    "\n",
    "# Creating our neural network model\n",
    "model = FCNN(d,s-1)\n",
    "\n",
    "# Setting the optimizer and setting the learning rate to decay\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=25000, gamma=0.1)\n",
    "\n",
    "L1_errors = []\n",
    "L2_errors = []\n",
    "eta  = (a-b)*torch.rand(J,d) + b\n",
    "\n",
    "\n",
    "for i in range(m):\n",
    "    model.train()\n",
    "    X_T  = brownian_motion.sample(eta,T)\n",
    "    loss = torch.mean((model(eta)[:,0]-phi(X_T))**2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    scheduler.step()\n",
    "    if i%10 == 0:\n",
    "        model.eval()\n",
    "        L1_errors.append(Lp_rel_error(model, u, a,b,d, 1000,1))\n",
    "        L2_errors.append(Lp_rel_error(model, u, a,b,d, 1000,2))\n",
    "        print(\"Step {} L1 error is {}, L2 error is {} and loss function value is {}\".format(i,L1_errors[-1],L2_errors[-1],loss))\n",
    "        \n",
    "        \n",
    "plt.plot(range(len(L1_errors)),L1_errors)\n",
    "plt.plot(range(len(L2_errors)),L2_errors)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
